\chapter{Realisation}
\label{ch:realisation}
\section{Expected components}
\subsection{Computation}
\subsubsection{Parsing input and data initialisation}
The first component of the calculator is responsible for parsing and initialising the state, element, and reagent manager objects with data extracted from the the given input through the command prompt. \\

Input form the command prompt given either by the user if used directly or thought the web interface is extracted into corresponding data structures for each cli parameter. Boost provides us with a robust and simple approach that also guarantees variable type safetyness. \\

Parsing of the given chemical formula is needed to convert the data from a simple string to a more usable format usable for creating the matrices utilised in generating solutions. This is achieved through the use of a "parse" function (snapshot/link to appendix) called twice, once for the string containing the stoichiometry chemical formula and then once again for the string with the reagents. The function splits the input on tokens based on the space character and then appplies a regex match function in order to further divide each token into elements, denoted by an uppercase character followed by an optional lowercase one. By explicitly saving up the unmatched results of the regex function, the integers denoting the quantity of each element present are also added into the new array of subtokens? (think about this). Finally, a reagent object is created by going through this array and pairing elements with quantities. At this stage the string generation functionality of the reagent class is invoked to construct and cache a corresponding readable chemical formula string.\\

Depending on on which mode the calculator is being used in, the resulting reagent for the stoich input is stored in a single reagent object, whilst the respective list of available reagents are stored inside a ragentdb object. If the mode is set to 0 (stoich mode), the reagentdb object will be filled with single-element reagents, each corresponding to one element and quantity from the stoich input, this is done as to simplify both generation of the matrix contents and csv exports later on. \\

ElementDB and StateDB inits go here. \\

\subsubsection{Generation of a solution and its null-space}
After the input data is properly organised into its respective containers, an array of pairs of matrices containing systems of linear equations is generated based on the stoich reagent and reagentdb object. If the calculator is run with mode = 0, only a single matrix pair is created, as the precursor matrix utilises different equations than the stoichiometry matrices, whilst the mode = 0 requires multiple matrix pairs to account for multiple charge states present for a single element. (hyperref to design to understand what im talking about?) \\

Each pair obtained now contains 2 matrices, a matrix of equations A and a matrix of "insert term here" B. For each pair, we use Eigen to solve AX = B [hyperref to design] we obtain a solution vector X as well as a kernel matrix K [more hyperref to design] \\

\subsubsection{Validation and generation of the finite solution-space}
The first solution and the matrix null-space generated by Eigen is then validated and used to generate a finite number of solutions correspnding to the user specified number of samples. The most basic criterion for validation is if the solution contains all-positive real values, with all solutions with even one negative value not being added into the solutionDB object. The only other criterion for validation is if the newly computed solution $S_{x} = X + v_{1}C_{1} + ... + v_{n}C_{n}$ ($v_{1} ... v_{n}$ is a null-space vector and C is a combination with n being the number of null-space vectors/columns) satisfies $AS_{x} = B$ as $AX = B$ previously did. \\

$C_{n}$ is generated as the combination of nk with repetitions of a set of real values using the formula [insert formula here] with k being the number of null-space columns/vectors, and n being the size of the set. The set members are generated in an iterative manner going from 1 to a $1/max_denominator$ value, with 0 being added post-loop. The $max_denominator$ value is obtained by summing the square root of the desired number of samples and the averege number of negative null-space values per column. This approach aims to generate more combinations than samples required as if even a single null-space vector contains a negative value, it might cause several generated solutions to be negative and as such, yield less than the amount of samples requested by the user. 

At this point, the solution is nothing more than an arrray of real values, and must furst be transformed into an usable format before being delivered back to the user/webserver. A solution object is used to achieve this process, which contains the array of values itself, as well as ther rational approximation of each value and the total score of the solution. The rational approximation is computed using an algorithm proposed by David Eppstein (reference here) and used in rounding, as well as calculating the score of a solution. The score itself is calculated as the LCM (code image) of the denominators of each value present in the solution vector.

\subsubsection{Post-Computation trimming of uneeded results and output}
Finally the excess solution data in the solutiondb object that exceeds the amount of desired samples is discarded based on highest score (less desired), with the remaining data being processed to be exported into a csv file that can either be read by the user or is automatically loaded into the database by the webserver. \\

\subsection{Web server}
\subsubsection{Routing}


\section{Problems encountered}
This section will be used to enumerate problems encountered during the
implementation of the projectâ€™s goal. We present issues that have been found
a solution to, and fleshed out, but also issues that remain with the current
implementation. The remaining problems will present a potential solution
that can be implemented in the future. \\

\subsection*{Accuracy and Performance}
Our first approach of realising our design was with using Linear-Integer Programming (linear programming) optimisation tools using Gurobi and later on switching to Google based OR-tools. In both cases, performance was similar and satisfactory but we experienced a lack of control over the generation of solutions, as well as their accuracy when multiple solutions are concerned. In hindsight, this is to be expected as these approaches are primarily focused on optimising the primary solution, whereas we require good representation for a given number of desired solutions. Moreover whilst the solver by itself is fast, its initialisation is not, which presented an issue for the stoichiometry part as it required multiple nationalisations for different values of charges for each element. Finally, we had no way of requesting a specific amount of solutions from the solver other than the one presented to us, in most cases resulted with a disproportion of generated results compared to desired amount of samples. \\

Under the advise of Dr Vitaliy Kurlin, we switched to a more mathematical approach, utilising linear algebra to find one solution using LU decomposition and then using it afterwards to generate a potentially infinite solution-space using the kernel of the initial matrix of linear equations A. Using this approach we were able to gain control over how many solutions we present to the user, as well as tweak our performance issues with the stoichiometry functionality, as decomposing a matrix is far cost-effecting than re-initialising the entire solver backend with new data. \\

\subsection*{Combinatorial weights}
This was the longest and most persistent issue we had to deal with after switching from the approach of using solvers. As each new solution would be defined as $S_{x} = X + v_{1}N_{1} + ... + v_{n}N_{n}$ ($v_{1} ... v_{n}$ is a null-space vector and N being any real number) satisfies $AS_{x} = B$, we needed a way to obtain N in a meaninful way that also produces good representation. Unfortunately due our inexperience we took a very naive approach of generating all possible combinations C nk (formula here) of a set ranging from 0 to 1 using an varying iterator given as input parameter, usually 0.003 or 0.001 during testing. This produced varying problems for the performance of our application and would persist for most of the development time as we didn't consider speed and disk space efficiency a priorirty at that point in time, but would later be changed for a more optimised and smarter approach after receiving important feedback from the users in the MIF. (link to section) \\

To give an idea of how terrible of an approach this way, one of our more used tests, the chemical formula "LiAlSO" would produce a kernel with 2 null-space vectors and using the formula for combinations (insert formula here) would give C = 50,050,000 "initial" solutions, which would then have to be validated individually. On an laptop Intel i7 this test would take around 30 seconds if we were to generate all combinations every time. An approach to cache these combination into a generic text file that could be read when needed was taken to reduce computation time, but would only reduce it to roughly 12 seconds. This is in vast contrast to our final approach that takes as little as 0.02 seconds and generates only enough solutions to match the requests number of desired solutions. \\

\subsection*{Precision Errors}
Another key problem that was persistent for most of the development period was floating point precision errors, as we'd get solutions with 0.33334 and say, 0.3332323 for one of your very early "LiAlSO" tests. The apparent issue is that the program treated them as different solutions when they should have been interpreted as one the same, which created situations where the program would not give us our desired solutions when trying to replicate given test data. Initially our approach was to just cut down decimals, but when working with high precision and values that need to eventually need to be reproduced in real life this was not a desirable way moving forward. As such we decided to convert all real values into their respective rational representations (link to section), which for the 2 examples given above would output 1/3, thus solving our precision "errors".

\subsection*{3-Way Integration - Aaron}


\section{Testing}
Most components have been tested solely internally, only with the web-server being presented for user-testing for Dr. Berhard Leube, a colleague of Dr. Vitaly Kurlin and Dr. Mike Gaultois in the MIF. However, Dr. Mike Gaultois and Dr. Vladimir Gusev have been presented with results of isolated runs of the calculator component at various times during the development of the project. \\

The calculator is the brain of this project, and has been rightfully tested the most, although on limited input parameters due to our lack of chemical knowledge outside given synthesised compounds. The chemical formula "LiAlSO" would end up being our default test input, as it had four elements present, as well as five given precursors, "Li2S Al2S3 Al2O3 LiAlO2 Li2O", making it not too easy but not too complicated either for our O(insert running performance here) complexity. \\


stuff\\
Planned parallelism cut due to time constraints but code is more than ready for it \\